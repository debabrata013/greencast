{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing Pipeline\n",
    "\n",
    "This notebook handles image preprocessing, augmentation, and preparation for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Set paths\n",
    "PROJECT_ROOT = Path('/Users/debabratapattnayak/web-dev/greencast')\n",
    "DATASET_PATH = PROJECT_ROOT / 'dataset'\n",
    "PLANTVILLAGE_PATH = DATASET_PATH / 'plantvillage dataset'\n",
    "DATA2_PATH = DATASET_PATH / 'data2'\n",
    "PROCESSED_DATA_PATH = PROJECT_ROOT / 'processed_data'\n",
    "\n",
    "# Create processed data directories\n",
    "PROCESSED_DATA_PATH.mkdir(exist_ok=True)\n",
    "(PROCESSED_DATA_PATH / 'train').mkdir(exist_ok=True)\n",
    "(PROCESSED_DATA_PATH / 'validation').mkdir(exist_ok=True)\n",
    "(PROCESSED_DATA_PATH / 'test').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor:\n",
    "    def __init__(self, target_size=(224, 224), normalize=True):\n",
    "        self.target_size = target_size\n",
    "        self.normalize = normalize\n",
    "        \n",
    "    def resize_image(self, image, maintain_aspect_ratio=True):\n",
    "        \"\"\"Resize image to target size\"\"\"\n",
    "        if maintain_aspect_ratio:\n",
    "            # Calculate aspect ratio\n",
    "            h, w = image.shape[:2]\n",
    "            aspect_ratio = w / h\n",
    "            \n",
    "            if aspect_ratio > 1:  # Width > Height\n",
    "                new_w = self.target_size[0]\n",
    "                new_h = int(new_w / aspect_ratio)\n",
    "            else:  # Height >= Width\n",
    "                new_h = self.target_size[1]\n",
    "                new_w = int(new_h * aspect_ratio)\n",
    "            \n",
    "            # Resize image\n",
    "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # Pad to target size\n",
    "            delta_w = self.target_size[0] - new_w\n",
    "            delta_h = self.target_size[1] - new_h\n",
    "            top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "            left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "            \n",
    "            # Pad with mean color\n",
    "            mean_color = np.mean(resized, axis=(0, 1))\n",
    "            padded = cv2.copyMakeBorder(resized, top, bottom, left, right, \n",
    "                                      cv2.BORDER_CONSTANT, value=mean_color)\n",
    "            return padded\n",
    "        else:\n",
    "            return cv2.resize(image, self.target_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    def normalize_image(self, image):\n",
    "        \"\"\"Normalize image pixel values\"\"\"\n",
    "        if self.normalize:\n",
    "            return image.astype(np.float32) / 255.0\n",
    "        return image\n",
    "    \n",
    "    def enhance_image(self, image, enhance_contrast=True, enhance_brightness=True):\n",
    "        \"\"\"Apply image enhancements\"\"\"\n",
    "        # Convert to PIL for enhancements\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        if enhance_contrast:\n",
    "            enhancer = ImageEnhance.Contrast(pil_image)\n",
    "            pil_image = enhancer.enhance(1.2)  # Increase contrast by 20%\n",
    "        \n",
    "        if enhance_brightness:\n",
    "            enhancer = ImageEnhance.Brightness(pil_image)\n",
    "            pil_image = enhancer.enhance(1.1)  # Increase brightness by 10%\n",
    "        \n",
    "        # Convert back to OpenCV format\n",
    "        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    def remove_noise(self, image):\n",
    "        \"\"\"Apply noise reduction\"\"\"\n",
    "        # Apply bilateral filter to reduce noise while preserving edges\n",
    "        return cv2.bilateralFilter(image, 9, 75, 75)\n",
    "    \n",
    "    def preprocess_image(self, image_path, apply_enhancements=True):\n",
    "        \"\"\"Complete preprocessing pipeline for a single image\"\"\"\n",
    "        try:\n",
    "            # Load image\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Could not load image: {image_path}\")\n",
    "            \n",
    "            # Apply enhancements if requested\n",
    "            if apply_enhancements:\n",
    "                image = self.enhance_image(image)\n",
    "                image = self.remove_noise(image)\n",
    "            \n",
    "            # Resize image\n",
    "            image = self.resize_image(image)\n",
    "            \n",
    "            # Convert to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Normalize\n",
    "            image = self.normalize_image(image)\n",
    "            \n",
    "            return image\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error preprocessing {image_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = ImagePreprocessor(target_size=(224, 224))\n",
    "print(\"Image preprocessor initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators():\n",
    "    \"\"\"Create data generators for training, validation, and testing\"\"\"\n",
    "    \n",
    "    # Training data generator with augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        channel_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    # Validation and test data generators (no augmentation)\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    return train_datagen, val_test_datagen\n",
    "\n",
    "def visualize_augmentation(image_path, num_augmented=8):\n",
    "    \"\"\"Visualize data augmentation effects\"\"\"\n",
    "    # Load original image\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    \n",
    "    # Create augmentation generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "    \n",
    "    # Generate augmented images\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Show original\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Generate and show augmented versions\n",
    "    i = 1\n",
    "    for batch in datagen.flow(x, batch_size=1):\n",
    "        if i >= num_augmented:\n",
    "            break\n",
    "        axes[i].imshow(batch[0].astype('uint8'))\n",
    "        axes[i].set_title(f'Augmented {i}')\n",
    "        axes[i].axis('off')\n",
    "        i += 1\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create data generators\n",
    "train_datagen, val_test_datagen = create_data_generators()\n",
    "print(\"Data generators created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Organization and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_dataset(source_path, output_path, test_split=0.15, val_split=0.15):\n",
    "    \"\"\"Organize dataset into train/val/test splits\"\"\"\n",
    "    \n",
    "    # Create output directories\n",
    "    train_dir = output_path / 'train'\n",
    "    val_dir = output_path / 'validation'\n",
    "    test_dir = output_path / 'test'\n",
    "    \n",
    "    train_dir.mkdir(exist_ok=True)\n",
    "    val_dir.mkdir(exist_ok=True)\n",
    "    test_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Get all class directories\n",
    "    class_dirs = [d for d in os.listdir(source_path) \n",
    "                  if os.path.isdir(os.path.join(source_path, d))]\n",
    "    \n",
    "    dataset_info = {\n",
    "        'classes': [],\n",
    "        'train_counts': {},\n",
    "        'val_counts': {},\n",
    "        'test_counts': {},\n",
    "        'total_images': 0\n",
    "    }\n",
    "    \n",
    "    for class_name in tqdm(class_dirs, desc=\"Processing classes\"):\n",
    "        class_path = os.path.join(source_path, class_name)\n",
    "        \n",
    "        # Get all images in this class\n",
    "        images = [f for f in os.listdir(class_path) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "        \n",
    "        if len(images) < 10:  # Skip classes with too few images\n",
    "            print(f\"Skipping {class_name}: only {len(images)} images\")\n",
    "            continue\n",
    "        \n",
    "        # Create class directories in output\n",
    "        (train_dir / class_name).mkdir(exist_ok=True)\n",
    "        (val_dir / class_name).mkdir(exist_ok=True)\n",
    "        (test_dir / class_name).mkdir(exist_ok=True)\n",
    "        \n",
    "        # Split images\n",
    "        np.random.shuffle(images)\n",
    "        \n",
    "        n_test = int(len(images) * test_split)\n",
    "        n_val = int(len(images) * val_split)\n",
    "        n_train = len(images) - n_test - n_val\n",
    "        \n",
    "        train_images = images[:n_train]\n",
    "        val_images = images[n_train:n_train + n_val]\n",
    "        test_images = images[n_train + n_val:]\n",
    "        \n",
    "        # Copy images to respective directories\n",
    "        for img in train_images:\n",
    "            src = os.path.join(class_path, img)\n",
    "            dst = train_dir / class_name / img\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        for img in val_images:\n",
    "            src = os.path.join(class_path, img)\n",
    "            dst = val_dir / class_name / img\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        for img in test_images:\n",
    "            src = os.path.join(class_path, img)\n",
    "            dst = test_dir / class_name / img\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        # Update dataset info\n",
    "        dataset_info['classes'].append(class_name)\n",
    "        dataset_info['train_counts'][class_name] = len(train_images)\n",
    "        dataset_info['val_counts'][class_name] = len(val_images)\n",
    "        dataset_info['test_counts'][class_name] = len(test_images)\n",
    "        dataset_info['total_images'] += len(images)\n",
    "    \n",
    "    # Save dataset info\n",
    "    with open(output_path / 'dataset_info.json', 'w') as f:\n",
    "        json.dump(dataset_info, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nDataset organization complete!\")\n",
    "    print(f\"Total classes: {len(dataset_info['classes'])}\")\n",
    "    print(f\"Total images: {dataset_info['total_images']}\")\n",
    "    print(f\"Train images: {sum(dataset_info['train_counts'].values())}\")\n",
    "    print(f\"Validation images: {sum(dataset_info['val_counts'].values())}\")\n",
    "    print(f\"Test images: {sum(dataset_info['test_counts'].values())}\")\n",
    "    \n",
    "    return dataset_info\n",
    "\n",
    "# Organize PlantVillage color dataset\n",
    "plantvillage_color_path = PLANTVILLAGE_PATH / 'color'\n",
    "if plantvillage_color_path.exists():\n",
    "    print(\"Organizing PlantVillage color dataset...\")\n",
    "    pv_dataset_info = organize_dataset(\n",
    "        plantvillage_color_path, \n",
    "        PROCESSED_DATA_PATH / 'plantvillage_color'\n",
    "    )\n",
    "else:\n",
    "    print(\"PlantVillage color dataset not found!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
