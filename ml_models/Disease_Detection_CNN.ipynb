{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔬 Plant Disease Detection using CNN with Transfer Learning\n",
        "\n",
        "This notebook implements MobileNetV2 and ResNet50 for plant disease classification using transfer learning.\n",
        "\n",
        "## Features:\n",
        "- Transfer Learning with pre-trained models\n",
        "- Multi-class disease classification\n",
        "- Data augmentation pipeline\n",
        "- Two-phase training (frozen + fine-tuning)\n",
        "- Confidence scoring for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📚 Libraries imported successfully!\n",
            "TensorFlow version: 2.20.0-rc0\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Utils\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"📚 Libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 Dataset path: /Users/debabratapattnayak/web-dev/greencast/processed_data/plantvillage_color_symlinks\n",
            "📁 Models will be saved to: /Users/debabratapattnayak/web-dev/greencast/ml_models/trained_models\n",
            "📁 Results will be saved to: /Users/debabratapattnayak/web-dev/greencast/ml_models/results\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "MODEL_TYPE = 'mobilenetv2'  # Change to 'resnet50' if preferred\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "FINE_TUNE_EPOCHS = 10\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = Path(\"/Users/debabratapattnayak/web-dev/greencast\")\n",
        "DATASET_PATH = BASE_PATH / \"processed_data\" / \"plantvillage_color_symlinks\"\n",
        "MODELS_PATH = BASE_PATH / \"ml_models\" / \"trained_models\"\n",
        "RESULTS_PATH = BASE_PATH / \"ml_models\" / \"results\"\n",
        "\n",
        "# Create directories\n",
        "MODELS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"📁 Dataset path: {DATASET_PATH}\")\n",
        "print(f\"📁 Models will be saved to: {MODELS_PATH}\")\n",
        "print(f\"📁 Results will be saved to: {RESULTS_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Found 38 disease classes\n",
            "🏷️ Sample classes: ['Strawberry___healthy', 'Grape___Black_rot', 'Potato___Early_blight', 'Blueberry___healthy', 'Corn_(maize)___healthy']...\n",
            "\n",
            "📈 Sample class distribution:\n",
            "  Strawberry___healthy: 320 images\n",
            "  Grape___Black_rot: 826 images\n",
            "  Potato___Early_blight: 700 images\n",
            "  Blueberry___healthy: 1052 images\n",
            "  Corn_(maize)___healthy: 814 images\n"
          ]
        }
      ],
      "source": [
        "# Check dataset and count classes\n",
        "if not DATASET_PATH.exists():\n",
        "    print(f\"❌ Dataset not found at: {DATASET_PATH}\")\n",
        "    print(\"Please ensure the processed dataset exists.\")\n",
        "else:\n",
        "    train_path = DATASET_PATH / 'train'\n",
        "    if train_path.exists():\n",
        "        classes = [d.name for d in train_path.iterdir() if d.is_dir()]\n",
        "        num_classes = len(classes)\n",
        "        \n",
        "        print(f\"📊 Found {num_classes} disease classes\")\n",
        "        print(f\"🏷️ Sample classes: {classes[:5]}...\" if len(classes) > 5 else f\"🏷️ Classes: {classes}\")\n",
        "        \n",
        "        # Count images per class (sample)\n",
        "        class_counts = {}\n",
        "        for class_name in classes[:5]:  # Check first 5 classes\n",
        "            class_path = train_path / class_name\n",
        "            image_count = 0\n",
        "            for ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG', '*.png', '*.PNG']:\n",
        "                image_count += len(list(class_path.glob(ext)))\n",
        "            class_counts[class_name] = image_count\n",
        "        \n",
        "        print(f\"\\n📈 Sample class distribution:\")\n",
        "        for class_name, count in class_counts.items():\n",
        "            print(f\"  {class_name}: {count} images\")\n",
        "    else:\n",
        "        print(f\"❌ Training data not found at: {train_path}\")\n",
        "        num_classes = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Data Preparation\n",
        "\n",
        "Create data generators with augmentation for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 Creating data generators from: /Users/debabratapattnayak/web-dev/greencast/processed_data/plantvillage_color_symlinks\n",
            "Found 30453 images belonging to 38 classes.\n",
            "Found 7594 images belonging to 38 classes.\n",
            "Found 8129 images belonging to 38 classes.\n",
            "✅ Data generators created!\n",
            "📊 Training samples: 30453\n",
            "📊 Validation samples: 7594\n",
            "📊 Test samples: 8129\n",
            "🏷️ Classes (38): ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy']...\n"
          ]
        }
      ],
      "source": [
        "def create_data_generators(dataset_path, batch_size=32, validation_split=0.2):\n",
        "    \"\"\"Create data generators for training\"\"\"\n",
        "    \n",
        "    print(f\"📁 Creating data generators from: {dataset_path}\")\n",
        "    \n",
        "    # Data augmentation for training\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    \n",
        "    # Only rescaling for validation\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    \n",
        "    # Create generators\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        dataset_path / 'train',\n",
        "        target_size=INPUT_SHAPE[:2],\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        shuffle=True\n",
        "    )\n",
        "    \n",
        "    validation_generator = val_datagen.flow_from_directory(\n",
        "        dataset_path / 'train',\n",
        "        target_size=INPUT_SHAPE[:2],\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='validation',\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # Test generator (if test directory exists)\n",
        "    test_generator = None\n",
        "    if (dataset_path / 'test').exists():\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        test_generator = test_datagen.flow_from_directory(\n",
        "            dataset_path / 'test',\n",
        "            target_size=INPUT_SHAPE[:2],\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            shuffle=False\n",
        "        )\n",
        "    \n",
        "    print(f\"✅ Data generators created!\")\n",
        "    print(f\"📊 Training samples: {train_generator.samples}\")\n",
        "    print(f\"📊 Validation samples: {validation_generator.samples}\")\n",
        "    if test_generator:\n",
        "        print(f\"📊 Test samples: {test_generator.samples}\")\n",
        "    \n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "# Create data generators\n",
        "if DATASET_PATH.exists() and num_classes > 0:\n",
        "    train_gen, val_gen, test_gen = create_data_generators(DATASET_PATH, BATCH_SIZE)\n",
        "    \n",
        "    # Store class information\n",
        "    class_indices = train_gen.class_indices\n",
        "    class_names = list(class_indices.keys())\n",
        "    \n",
        "    print(f\"🏷️ Classes ({len(class_names)}): {class_names[:5]}...\")\n",
        "else:\n",
        "    print(\"❌ Cannot create data generators without valid dataset\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
