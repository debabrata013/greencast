{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ Plant Disease Detection using CNN with Transfer Learning\n",
        "\n",
        "This notebook implements MobileNetV2 and ResNet50 for plant disease classification using transfer learning.\n",
        "\n",
        "## Features:\n",
        "- Transfer Learning with pre-trained models\n",
        "- Multi-class disease classification\n",
        "- Data augmentation pipeline\n",
        "- Two-phase training (frozen + fine-tuning)\n",
        "- Confidence scoring for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Libraries imported successfully!\n",
            "TensorFlow version: 2.20.0-rc0\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Utils\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"üìö Libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Dataset path: /Users/debabratapattnayak/web-dev/greencast/processed_data/plantvillage_color_symlinks\n",
            "üìÅ Models will be saved to: /Users/debabratapattnayak/web-dev/greencast/ml_models/trained_models\n",
            "üìÅ Results will be saved to: /Users/debabratapattnayak/web-dev/greencast/ml_models/results\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "MODEL_TYPE = 'mobilenetv2'  # Change to 'resnet50' if preferred\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "FINE_TUNE_EPOCHS = 10\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = Path(\"/Users/debabratapattnayak/web-dev/greencast\")\n",
        "DATASET_PATH = BASE_PATH / \"processed_data\" / \"plantvillage_color_symlinks\"\n",
        "MODELS_PATH = BASE_PATH / \"ml_models\" / \"trained_models\"\n",
        "RESULTS_PATH = BASE_PATH / \"ml_models\" / \"results\"\n",
        "\n",
        "# Create directories\n",
        "MODELS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Dataset path: {DATASET_PATH}\")\n",
        "print(f\"üìÅ Models will be saved to: {MODELS_PATH}\")\n",
        "print(f\"üìÅ Results will be saved to: {RESULTS_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Found 38 disease classes\n",
            "üè∑Ô∏è Sample classes: ['Strawberry___healthy', 'Grape___Black_rot', 'Potato___Early_blight', 'Blueberry___healthy', 'Corn_(maize)___healthy']...\n",
            "\n",
            "üìà Sample class distribution:\n",
            "  Strawberry___healthy: 320 images\n",
            "  Grape___Black_rot: 826 images\n",
            "  Potato___Early_blight: 700 images\n",
            "  Blueberry___healthy: 1052 images\n",
            "  Corn_(maize)___healthy: 814 images\n"
          ]
        }
      ],
      "source": [
        "# Check dataset and count classes\n",
        "if not DATASET_PATH.exists():\n",
        "    print(f\"‚ùå Dataset not found at: {DATASET_PATH}\")\n",
        "    print(\"Please ensure the processed dataset exists.\")\n",
        "else:\n",
        "    train_path = DATASET_PATH / 'train'\n",
        "    if train_path.exists():\n",
        "        classes = [d.name for d in train_path.iterdir() if d.is_dir()]\n",
        "        num_classes = len(classes)\n",
        "        \n",
        "        print(f\"üìä Found {num_classes} disease classes\")\n",
        "        print(f\"üè∑Ô∏è Sample classes: {classes[:5]}...\" if len(classes) > 5 else f\"üè∑Ô∏è Classes: {classes}\")\n",
        "        \n",
        "        # Count images per class (sample)\n",
        "        class_counts = {}\n",
        "        for class_name in classes[:5]:  # Check first 5 classes\n",
        "            class_path = train_path / class_name\n",
        "            image_count = 0\n",
        "            for ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG', '*.png', '*.PNG']:\n",
        "                image_count += len(list(class_path.glob(ext)))\n",
        "            class_counts[class_name] = image_count\n",
        "        \n",
        "        print(f\"\\nüìà Sample class distribution:\")\n",
        "        for class_name, count in class_counts.items():\n",
        "            print(f\"  {class_name}: {count} images\")\n",
        "    else:\n",
        "        print(f\"‚ùå Training data not found at: {train_path}\")\n",
        "        num_classes = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Data Preparation\n",
        "\n",
        "Create data generators with augmentation for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Creating data generators from: /Users/debabratapattnayak/web-dev/greencast/processed_data/plantvillage_color_symlinks\n",
            "Found 30453 images belonging to 38 classes.\n",
            "Found 7594 images belonging to 38 classes.\n",
            "Found 8129 images belonging to 38 classes.\n",
            "‚úÖ Data generators created!\n",
            "üìä Training samples: 30453\n",
            "üìä Validation samples: 7594\n",
            "üìä Test samples: 8129\n",
            "üè∑Ô∏è Classes (38): ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy']...\n"
          ]
        }
      ],
      "source": [
        "def create_data_generators(dataset_path, batch_size=32, validation_split=0.2):\n",
        "    \"\"\"Create data generators for training\"\"\"\n",
        "    \n",
        "    print(f\"üìÅ Creating data generators from: {dataset_path}\")\n",
        "    \n",
        "    # Data augmentation for training\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    \n",
        "    # Only rescaling for validation\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "    \n",
        "    # Create generators\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        dataset_path / 'train',\n",
        "        target_size=INPUT_SHAPE[:2],\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        shuffle=True\n",
        "    )\n",
        "    \n",
        "    validation_generator = val_datagen.flow_from_directory(\n",
        "        dataset_path / 'train',\n",
        "        target_size=INPUT_SHAPE[:2],\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='validation',\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # Test generator (if test directory exists)\n",
        "    test_generator = None\n",
        "    if (dataset_path / 'test').exists():\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        test_generator = test_datagen.flow_from_directory(\n",
        "            dataset_path / 'test',\n",
        "            target_size=INPUT_SHAPE[:2],\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            shuffle=False\n",
        "        )\n",
        "    \n",
        "    print(f\"‚úÖ Data generators created!\")\n",
        "    print(f\"üìä Training samples: {train_generator.samples}\")\n",
        "    print(f\"üìä Validation samples: {validation_generator.samples}\")\n",
        "    if test_generator:\n",
        "        print(f\"üìä Test samples: {test_generator.samples}\")\n",
        "    \n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "# Create data generators\n",
        "if DATASET_PATH.exists() and num_classes > 0:\n",
        "    train_gen, val_gen, test_gen = create_data_generators(DATASET_PATH, BATCH_SIZE)\n",
        "    \n",
        "    # Store class information\n",
        "    class_indices = train_gen.class_indices\n",
        "    class_names = list(class_indices.keys())\n",
        "    \n",
        "    print(f\"üè∑Ô∏è Classes ({len(class_names)}): {class_names[:5]}...\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot create data generators without valid dataset\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
